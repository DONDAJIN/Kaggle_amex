{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp006.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "mount_file_id": "1uMO6DBMlIs2rGJIZ6eSWJ5rOBX8VunSh",
      "authorship_tag": "ABX9TyNu+aa9E2F0XL1TLouj2ZcD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DONDAJIN/Kaggle_amex/blob/master/exp006.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4OCiluimkjCU"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import joblib\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import lightgbm as lgb\n",
        "from itertools import combinations\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    seed = 42\n",
        "    n_folds = 5\n",
        "    target = 'target'\n",
        "    DIR='/content/drive/MyDrive/Kaggle'\n",
        "    INPUT= os.path.join(DIR,'Input')\n",
        "    OUTPUT=os.path.join(DIR,'Output')\n",
        "    EXP=os.path.join(DIR,'exp/exp006')\n",
        "    MODEL=os.path.join(EXP,'Model')\n",
        "    LOG=os.path.join(EXP,'Log')\n",
        "    PRED=os.path.join(EXP,'pred')\n",
        "    os.makedirs(EXP,exist_ok=True)\n",
        "    for i in ['Log','Model','pred']:\n",
        "      os.makedirs(os.path.join(EXP,i),exist_ok=True)\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def read_data():\n",
        "    train = pd.read_parquet(os.path.join(Config.INPUT,'train_fe_plus.parquet'))\n",
        "    test = pd.read_parquet(os.path.join(Config.INPUT,'test_fe_plus.parquet'))\n",
        "    return train, test\n",
        "\n",
        "def amex_metric(y_true, y_pred):\n",
        "    labels = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz = cum_pos_found / total_pos\n",
        "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "\n",
        "def amex_metric_np(preds, target):\n",
        "    indices = np.argsort(preds)[::-1]\n",
        "    preds, target = preds[indices], target[indices]\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_mask = cum_norm_weight <= 0.04\n",
        "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
        "    weighted_target = target * weight\n",
        "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "    n_pos = np.sum(target)\n",
        "    n_neg = target.shape[0] - n_pos\n",
        "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
        "    g = gini / gini_max\n",
        "    return 0.5 * (g + d)"
      ],
      "metadata": {
        "id": "O0m-bFh9k2h-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_difference(data,num_features):\n",
        "  df1=[]\n",
        "  customer_ids=[]\n",
        "  for customer_id,df in tqdm(data.groupby(['customer_ID'])): #groupbyオブジェクトfor文で回せる\n",
        "    diff_df1=df[num_features].diff(1).iloc[[-1]].values.astype('float32') #各customerの各列の差の最後の行\n",
        "    df1.append(diff_df1)\n",
        "    customer_ids.append(customer_id)\n",
        "  df1=np.concatenate(df1,axis=0)\n",
        "  df1=pd.DataFrame(df1,columns=[col+'_diff1' for col in df[num_features].columns])\n",
        "  df1['customer_ID']=customer_ids\n",
        "  return df1"
      ],
      "metadata": {
        "id": "s8ZRh0FOk9aU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_preprocess_data():\n",
        "  train=pd.read_parquet(os.path.join(Config.INPUT,'train.parquet'))\n",
        "  features=train.drop(['customer_ID','S_2'],axis=1).columns.to_list() #inplace=False\n",
        "  cat_features=[\n",
        "      'B_30',\n",
        "      'B_38',\n",
        "      'D_114',\n",
        "      'D_116',\n",
        "      'D_117',\n",
        "      'D_120',\n",
        "      'D_126',\n",
        "      'D_63',\n",
        "      'D_64',\n",
        "      'D_66',\n",
        "      'D_68',\n",
        "  ]\n",
        "  num_features=[col for col in features if col not in cat_features]\n",
        "  print('Starting training feature engineering-----------')\n",
        "  train_num_agg=train.groupby('customer_ID')[num_features].agg(['first','mean','std','min','max','last']) #n番目を取り出したいならnth(n)の関数もある\n",
        "  train_num_agg.columns=['_'.join(x) for x in train_num_agg.columns]# 'B_29','min'->'B_29_min'\n",
        "  train_num_agg.reset_index(inplace=True) #customerでくくった分indexがズレる\n",
        "  \n",
        "  #Lag features\n",
        "  for col in train_num_agg:\n",
        "    if 'last' in col and col.replace('last','first') in train_num_agg:  #例えばcol='B_12_last'なら'B_12_firstがあるなら進む\n",
        "      train_num_agg[col+'_lag_sub']=train_num_agg[col]-train_num_agg[col.replace('last','first')]\n",
        "      train_num_agg[col+'_lag_div']=train_num_agg[col]/train_num_agg[col.replace('last','first')]\n",
        "  \n",
        "  \n",
        "  train_cat_agg=train.groupby('customer_ID')[cat_features].agg(['count','first','last','nunique'])\n",
        "  train_cat_agg.columns=['_'.join(x) for x in train_cat_agg.columns]\n",
        "  train_cat_agg.reset_index(inplace=True)\n",
        "\n",
        "  train_lables=pd.read_csv(os.path.join(Config.INPUT,'train_labels.csv'))\n",
        "  \n",
        "  #Transform float64 columns to float32\n",
        "  cols=list(train_num_agg.dtypes[train_num_agg.dtypes=='float64'].index)\n",
        "  for col in tqdm(cols):\n",
        "    train_num_agg[col]=train_num_agg[col].astype(np.float32)\n",
        "  #Trasform int64 to int32\n",
        "  cols=list(train_cat_agg.dtypes[train_cat_agg.dtypes=='int64'].index)\n",
        "  for col in tqdm(cols):\n",
        "    train_cat_agg[col]=train_cat_agg[col].astype(np.int32)\n",
        "  \n",
        "  train_diff=get_difference(train,num_features)\n",
        "  train=train_num_agg.merge(train_cat_agg,how='inner',\n",
        "                            on='customer_ID').merge(train_diff,how='inner',on='customer_ID').merge(train_lables,how='inner',on='customer_ID')\n",
        "  del train_num_agg,train_diff,train_cat_agg\n",
        "  gc.collect()\n",
        "\n",
        "  #Test feature engineering\n",
        "  test=pd.read_parquet(os.path.join(Config.INPUT,'test.parquet'))\n",
        "  print('Start test feature engineering------------')\n",
        "  test_num_agg=test.groupby('customer_ID')[num_features].agg(['first','mean','std','min','max','last'])\n",
        "  test_num_agg.columns=['_'.join(x) for x in test_num_agg.columns]\n",
        "  test_num_agg.reset_index(inplace=True)\n",
        "\n",
        "  #Lag features\n",
        "  for col in test_num_agg:\n",
        "    if 'last' in col and col.replace('last','first') in test_num_agg:\n",
        "      test_num_agg[col+'_lag_sub']=test_num_agg[col]-test_num_agg[col.replace('last','first')]\n",
        "      test_num_agg[col+'_lag_div']=test_num_agg[col]/test_num_agg[col.replace('last','first')]\n",
        "\n",
        "  test_cat_agg=test.groupby('customer_ID')[cat_features].agg(['count','first','last','nunique'])\n",
        "  test_cat_agg.columns=['_'.join(x) for x in test_cat_agg.columns]\n",
        "  test_cat_agg.reset_index(inplace=True)\n",
        "\n",
        "  cols=list(test_num_agg.dtypes[test_num_agg.dtypes=='float64'].index) #dtypesではindexが列名\n",
        "  for col in tqdm(cols):\n",
        "    test_num_agg[col]=test_num_agg[col].astype(np.float32)\n",
        "\n",
        "  cols=list(test_cat_agg.dtypes[test_cat_agg.dtypes=='int64'].index)\n",
        "  for col in tqdm(cols):\n",
        "    test_cat_agg[col]=test_cat_agg[col].astype(np.int32)\n",
        "  \n",
        "  test_diff=get_difference(test,num_features)\n",
        "  test=test_num_agg.merge(test_cat_agg,how='inner',on='customer_ID').merge(test_diff,how='inner',on='customer_ID')\n",
        "  del test_num_agg,test_cat_agg,test_diff\n",
        "  gc.collect()\n",
        "  \n",
        "  train.to_parquet(os.path.join(Config.INPUT,'train_fe_plus.parquet'))\n",
        "  test.to_parquet(os.path.join(Config.INPUT,'test_fe_plus.parquet'))"
      ],
      "metadata": {
        "id": "6VLf8Ya8lCG3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_amex_metric(y_pred, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    return 'amex_metric', amex_metric(y_true, y_pred), True"
      ],
      "metadata": {
        "id": "4Kz3llnjlGUq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(train,test):\n",
        "  # Label encoding\n",
        "  cat_features=[\n",
        "      'B_30',\n",
        "      'B_38',\n",
        "      'D_114',\n",
        "      'D_116',\n",
        "      'D_117',\n",
        "      'D_120',\n",
        "      'D_126',\n",
        "      'D_63',\n",
        "      'D_64',\n",
        "      'D_66',\n",
        "      'D_68'\n",
        "      ]\n",
        "  cat_features=[f'{cf}_last' for cf in cat_features] #Preprocess後の'B_30_last'などにLabel encodingする\n",
        "  for cat_col in cat_features:\n",
        "    encoder=LabelEncoder()\n",
        "    train[cat_col]=encoder.fit_transform(train[cat_col])\n",
        "    test[cat_col]=encoder.transform(test[cat_col])\n",
        "\n",
        "  #Round last float features to 2 decimal place\n",
        "  num_cols=list(train.dtypes[(train.dtypes=='float32') | (train.dtypes=='float64')].index)\n",
        "  num_cols=[col for col in num_cols if 'last' in col] #lastが付いている列だけ\n",
        "  for col in num_cols:\n",
        "    train[col+'_round2']=train[col].round(2)\n",
        "    test[col+'_round2']=test[col].round(2)\n",
        "  \n",
        "  #Get the difference between last and mean\n",
        "  num_cols=[col for col in train.columns if 'last' in col] #lastが付いている列だけを取り出して\n",
        "  num_cols=[col[:-5] for col in num_cols if 'round' not in col] # 'B_2_last'から'B_2'\n",
        "  for col in num_cols:\n",
        "    try:\n",
        "      train[f'{col}_last_mean_diff']=train[f'{col}_last']-train[f'{col}_mean']\n",
        "      test[f'{col}_last_mean_diff']=test[f'{col}_last']-test[f'{col}_mean']\n",
        "    except:\n",
        "      pass\n",
        "  \n",
        "  #Transform float 64 and float 32 to float 16\n",
        "  num_cols=list(train.dtypes[(train.dtypes=='foat32') | (train.dtypes=='float16')].index)\n",
        "  for col in tqdm(num_cols):\n",
        "    train[col]=train[col].astype(np.float16)\n",
        "    test[col]=test[col].astype(np.float16)\n",
        "  #Get feature list\n",
        "  features=[col for col in train.columns if col not in ['customer_ID',Config.target]]\n",
        "  params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'None',\n",
        "        'boosting': 'gbdt',\n",
        "        'seed': Config.seed,\n",
        "        'num_leaves': 100,\n",
        "        'learning_rate': 0.01,\n",
        "        'feature_fraction': 0.20,\n",
        "        'bagging_freq': 10,\n",
        "        'bagging_fraction': 0.50,\n",
        "        'n_jobs': -1,\n",
        "        'lambda_l2': 2,\n",
        "        'min_data_in_leaf': 40\n",
        "        }\n",
        "  #Creat a numpy array to store test,oof predictions\n",
        "  test_predictions=np.zeros(len(test))\n",
        "  oof_predictions=np.zeros(len(train))\n",
        "\n",
        "  kfold=StratifiedKFold(n_splits=Config.n_folds,shuffle=True,random_state=Config.seed)\n",
        "  for fold,(tr_idx,val_idx) in enumerate(kfold.split(train,train[Config.target])):\n",
        "    print(' ')\n",
        "    print('-'*50)\n",
        "    print(f'Training fold {fold} with {len(features)} features...')\n",
        "    X_tr,X_val=train[features].iloc[tr_idx],train[features].iloc[val_idx]\n",
        "    y_tr,y_val=train[Config.target].iloc[tr_idx],train[Config.target].iloc[val_idx]\n",
        "\n",
        "    lgb_train=lgb.Dataset(X_tr,y_tr,categorical_feature=cat_features)\n",
        "    lgb_valid=lgb.Dataset(X_val,y_val,categorical_feature=cat_features)\n",
        "    model=lgb.train(\n",
        "        params=params,\n",
        "        train_set=lgb_train,\n",
        "        num_boost_round=20500,\n",
        "        valid_sets=[lgb_train,lgb_valid],\n",
        "        early_stopping_rounds=500,\n",
        "        verbose_eval=500,\n",
        "        feval=lgb_amex_metric,\n",
        "        fobj=None\n",
        "        )\n",
        "    #Save best model\n",
        "    joblib.dump(model,os.path.join(Config.MODEL,f'lgbm_fold{fold}_seed{Config.seed}.pkl'))\n",
        "\n",
        "    #Predict validation\n",
        "    val_pred=model.predict(X_val)\n",
        "\n",
        "    #Add to oof arrray\n",
        "    oof_predictions[val_idx]=val_pred\n",
        "\n",
        "    #Compute fold metric\n",
        "    score=amex_metric(y_val,val_pred)   #amex_metric(y_val[val_idx],val_pred[val_idx])?\n",
        "    print(f'Our Fold {fold} CV score is {score} ')\n",
        "    del X_tr,X_val,y_tr,y_val,lgb_train,lgb_valid\n",
        "    gc.collect()\n",
        "  \n",
        "  #Compute oof metric\n",
        "  score=amex_metric(train[Config.target],oof_predictions)\n",
        "  print(f'Our out of folds CV Score is {score}')\n",
        "\n",
        "  #Create a dataframe to store out of folds predictions\n",
        "  oof_df=pd.DataFrame({'customer_ID':train['customer_ID'],'target':train[Config.target],'Prediction':oof_predictions})\n",
        "  oof_df.to_csv(os.path.join(Config.PRED,'oof_lgbm_baseline_{Config.n_folds}fold_seed{Config.seed}.csv'),index=False)"
      ],
      "metadata": {
        "id": "-JnaUOxQlJUg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,test=read_data()\n",
        "train_and_evaluate(train,test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8h-thSJl3IQ",
        "outputId": "ce417d03-13c8-4c51-fbab-929d0ff42caf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "--------------------------------------------------\n",
            "Training fold 0 with 2177 features...\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's amex_metric: 0.811023\tvalid_1's amex_metric: 0.790055\n",
            "[1000]\ttraining's amex_metric: 0.843039\tvalid_1's amex_metric: 0.79704\n",
            "[1500]\ttraining's amex_metric: 0.869019\tvalid_1's amex_metric: 0.7993\n",
            "[2000]\ttraining's amex_metric: 0.893074\tvalid_1's amex_metric: 0.800472\n",
            "[2500]\ttraining's amex_metric: 0.91352\tvalid_1's amex_metric: 0.799837\n",
            "Early stopping, best iteration is:\n",
            "[2060]\ttraining's amex_metric: 0.895448\tvalid_1's amex_metric: 0.801356\n",
            "Our Fold 0 CV score is 0.8003417551764875 \n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 1 with 2177 features...\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's amex_metric: 0.812706\tvalid_1's amex_metric: 0.782239\n",
            "[1000]\ttraining's amex_metric: 0.844633\tvalid_1's amex_metric: 0.790108\n",
            "[1500]\ttraining's amex_metric: 0.870487\tvalid_1's amex_metric: 0.792853\n",
            "[2000]\ttraining's amex_metric: 0.893993\tvalid_1's amex_metric: 0.792575\n",
            "Early stopping, best iteration is:\n",
            "[1736]\ttraining's amex_metric: 0.882187\tvalid_1's amex_metric: 0.793604\n",
            "Our Fold 1 CV score is 0.793431934963301 \n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 2 with 2177 features...\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's amex_metric: 0.812069\tvalid_1's amex_metric: 0.787404\n",
            "[1000]\ttraining's amex_metric: 0.844105\tvalid_1's amex_metric: 0.793728\n",
            "[1500]\ttraining's amex_metric: 0.870231\tvalid_1's amex_metric: 0.794883\n",
            "[2000]\ttraining's amex_metric: 0.893532\tvalid_1's amex_metric: 0.795596\n",
            "[2500]\ttraining's amex_metric: 0.914552\tvalid_1's amex_metric: 0.795681\n",
            "[3000]\ttraining's amex_metric: 0.932328\tvalid_1's amex_metric: 0.796286\n",
            "Early stopping, best iteration is:\n",
            "[2609]\ttraining's amex_metric: 0.918425\tvalid_1's amex_metric: 0.796832\n",
            "Our Fold 2 CV score is 0.7964457351685321 \n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 3 with 2177 features...\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's amex_metric: 0.813292\tvalid_1's amex_metric: 0.780815\n",
            "[1000]\ttraining's amex_metric: 0.844959\tvalid_1's amex_metric: 0.787921\n",
            "[1500]\ttraining's amex_metric: 0.871272\tvalid_1's amex_metric: 0.789288\n",
            "[2000]\ttraining's amex_metric: 0.894168\tvalid_1's amex_metric: 0.789809\n",
            "[2500]\ttraining's amex_metric: 0.914747\tvalid_1's amex_metric: 0.790875\n",
            "[3000]\ttraining's amex_metric: 0.932413\tvalid_1's amex_metric: 0.791423\n",
            "[3500]\ttraining's amex_metric: 0.947545\tvalid_1's amex_metric: 0.791829\n",
            "[4000]\ttraining's amex_metric: 0.960593\tvalid_1's amex_metric: 0.791627\n",
            "Early stopping, best iteration is:\n",
            "[3941]\ttraining's amex_metric: 0.959104\tvalid_1's amex_metric: 0.792406\n",
            "Our Fold 3 CV score is 0.7916029777467186 \n",
            " \n",
            "--------------------------------------------------\n",
            "Training fold 4 with 2177 features...\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's amex_metric: 0.81222\tvalid_1's amex_metric: 0.785272\n",
            "[1000]\ttraining's amex_metric: 0.844155\tvalid_1's amex_metric: 0.792977\n",
            "[1500]\ttraining's amex_metric: 0.869458\tvalid_1's amex_metric: 0.796108\n",
            "[2000]\ttraining's amex_metric: 0.89312\tvalid_1's amex_metric: 0.796216\n",
            "[2500]\ttraining's amex_metric: 0.91336\tvalid_1's amex_metric: 0.796655\n",
            "Early stopping, best iteration is:\n",
            "[2491]\ttraining's amex_metric: 0.913076\tvalid_1's amex_metric: 0.796948\n",
            "Our Fold 4 CV score is 0.7968243772864114 \n",
            "Our out of folds CV Score is 0.7957904618949605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CV:0.79579"
      ],
      "metadata": {
        "id": "6dLHtJ-HJpt_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=[]\n",
        "for i in range(5):\n",
        "  model=joblib.load(os.path.join(Config.MODEL,f'lgbm_fold{i}_seed{Config.seed}.pkl'))\n",
        "  models.append(model)"
      ],
      "metadata": {
        "id": "u9L2st__mFRZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the test set\n",
        "test=pd.read_parquet(os.path.join(Config.INPUT,'test_fe_plus.parquet'))\n",
        "features=[col for col in test.columns if col not in ['customer_ID',Config.target]]\n",
        "test_predictions=np.zeros(len(test))\n",
        "for model in models:\n",
        "  test_pred=model.predict(test[features])\n",
        "  test_predictions+=test_pred/Config.n_folds\n",
        "#Create a dataframe to store test predictions\n",
        "test_df=pd.DataFrame({'customer_ID':test['customer_ID'],'prediction':test_predictions})\n",
        "test_df.to_csv(os.path.join(Config.PRED,f'test_lgbm_baseline_{Config.n_folds}fold_seed{Config.seed}.csv'),index=False)"
      ],
      "metadata": {
        "id": "1kmbFZvumSWT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YVy_A1veJuFD",
        "outputId": "68b94dc0-977b-44be-aaed-4f74427efb6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         customer_ID  prediction\n",
              "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.073672\n",
              "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.007000\n",
              "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.056113\n",
              "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.283631\n",
              "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.725476"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a75eae1-e98c-4820-8b42-d140167710b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_ID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
              "      <td>0.073672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
              "      <td>0.056113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
              "      <td>0.283631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
              "      <td>0.725476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a75eae1-e98c-4820-8b42-d140167710b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a75eae1-e98c-4820-8b42-d140167710b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a75eae1-e98c-4820-8b42-d140167710b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LB: 0.785"
      ],
      "metadata": {
        "id": "HyQZqQHWNHRp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vk46NXqrNOcn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}